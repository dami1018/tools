
import torch
import torch.nn as nn
import torch.nn.functional as F
# 1、模型定义
def self_attention(q,k,v):
    dim = torch.tensor(q.size(-1))
    weight = q @ k.transpose(-2,-1)/torch.sqrt(dim)
    weight_prob = F.log_softmax(weight,dim=-1)
    return weight_prob @ v
class multi_attention(nn.Module):
    def __init__(self,head,embed_dim,dropout):
        super(multi_attention,self).__init__()
        self.fc = nn.ModuleList(nn.Linear(embed_dim, embed_dim) for _ in range(4))
        self.head_dim = embed_dim // head
        self.head = head
        self.embed_dim = embed_dim
        self.dropout = nn.Dropout(p=dropout)
    def forward(self,q,k,v):
        batch_num = q.size(0)
        q,k,v = [ l(x).view(batch_num,-1,self.head,self.head_dim).transpose(1,2) for l,x in zip(self.fc,(q,k,v))]
        x = self_attention(q, k, v)
        x = x.transpose(1,2).contiguous().view(batch_num,-1,self.head*self.head_dim)
        return self.fc[-1](x)
class feedforward(nn.Module):
    def __init__(self,embed_dim,hidden_dim,dropout=0.1):
        super(feedforward,self).__init__()
        self.lin1 = nn.Linear(embed_dim, hidden_dim)
        self.lin2 = nn.Linear(hidden_dim, embed_dim)
        self.dropout = nn.Dropout(p=dropout)
    def forward(self,x):
        return self.lin2(self.dropout(F.relu(self.lin1(x))))
class layernorm(nn.Module):
    def __init__(self,embed_dim,eps=1e-6):
        super(layernorm,self).__init__()
        self.w = nn.Parameter(torch.ones(embed_dim))
        self.b = nn.Parameter(torch.zeros(embed_dim))
        self.eps = eps
    def forward(self,x):
        mean = x.mean(dim=-1,keepdim=True)
        std = x.std(dim=-1,keepdim=True)
        return self.w * ((x - mean) / (std + self.eps)) + self.b
class generator(nn.Module):
    def __init__(self,embed_dim,out_dim):
        super(generator,self).__init__()
        self.fc = nn.Linear(embed_dim, out_dim)
    def forward(self,x):
        return F.log_softmax(self.fc(x).squeeze(dim=-1),dim=-1)
class encoderlayer(nn.Module):
    def __init__(self,head,embed_dim,hidden_dim,dropout=0.1):
        super(encoderlayer,self).__init__()
        self.norm = nn.ModuleList(layernorm(embed_dim) for _ in range(2))
        self.attention = multi_attention(head, embed_dim, dropout)
        self.dropout = nn.Dropout(p=dropout)
        self.feedforward = feedforward(embed_dim, hidden_dim)
    def forward(self,x):
        x_norm = self.norm[0](x)
        x_bias = self.attention(x_norm,x_norm,x_norm)
        x_1 = x + self.dropout(x_bias)
        x_norm_feed = self.norm[1](x_1) 
        x_feed_bias = self.feedforward(x_norm_feed)
        x_2 = x_1 + self.dropout(x_feed_bias)
        return(x_2)
class Encoder(nn.Module):
    def __init__(self,layer_num,head,embed_dim,hidden_dim,out_dim=1,dropout=0.1):
        super(Encoder,self).__init__()
        self.encoder = nn.ModuleList(encoderlayer(head, embed_dim, hidden_dim) for _ in range(layer_num))
        self.generator = generator(embed_dim,out_dim)
    def forward(self,x):
        x_1 = self.encoder[0](x)
        x_2 = self.encoder[1](x_1)
        return self.generator((x_2))
    
def distance_simple(x,y):
    loss = torch.tensor(0,dtype=torch.float32)
    x = x.view(-1,x.size(-1))
    y = y.view(-1,y.size(-1))
    # res = []
    for k in range(x.size(0)):
        for i in range(x.size(1)):
            for j in range(i+1,x.size(1)):
                # res.append((k,i,j,loss.item()))
                if (~torch.isnan(x[k,i]))&(~torch.isnan(x[k,j])):
                    loss += F.relu(-(x[k,i] - x[k,j])*(y[k,i]-y[k,j])/torch.abs(y[k,i]-y[k,j]))            
    # return loss
    return (2*loss/(x.size(1)*(x.size(1)-1)*x.size(0)))
def distance_simple_improved(x,y):
    loss = torch.tensor(0,dtype=torch.float32)
    x = x.view(-1,x.size(-1))
    y = y.view(-1,y.size(-1))
    # res = []
    for k in range(x.size(0)):
        for i in range(x.size(1)):
            for j in range(i+1,x.size(1)):
                # res.append((k,i,j,loss.item()))
                if (~torch.isnan(x[k,i]))&(~torch.isnan(x[k,j])):
                    loss += F.relu(-(x[k,i] - x[k,j])*(y[k,i]-y[k,j])/torch.abs(y[k,i]-y[k,j]))            
    # return loss
    return (2*loss/(x.size(1)*(x.size(1)-1)*x.size(0)))

head = 1
embed_dim = 1210
dropout = 0.1
hidden_dim = 256
layer_num = 2
lr = 0.01
epoch = 100
encoder = Encoder(layer_num, head, embed_dim, hidden_dim)
# data_group_in_pt 有0 对datagroup进行了修改
data_group_in_pt = torch.tensor(torch.randn(28,31,1210),dtype=torch.float32)
# y_pred = encoder(data_group_in_pt)
y_sort_pt = torch.tensor(torch.randn(28,31),dtype=torch.float32)
from torch.utils.tensorboard import SummaryWriter
writer = SummaryWriter()
writer.add_graph(encoder, data_group_in_pt)
import torch.optim as optim
optimizer = optim.Adam(encoder.parameters(),lr=0.001)

# 终于知道为什么了，换个浏览器，google的就可以
# 1、损失函数1，自定义的
# 损失函数太大了，到底使不使用logsoftmax
# 损失函数交叉计算，用两个损失函数，来训练模型
# tensorboard --logdir=runs --bind_all
for i in range(epoch):    
    encoder.train()
    optimizer.zero_grad()
    y_pred = encoder(data_group_in_pt)
    loss = distance_simple(y_pred, y_sort_pt)
    # loss.requires_grad_(True)
    loss.backward()
    optimizer.step()
    print(f"Epoch {i}, Loss: {loss.item()}")
    writer.add_scalar('Training Loss', loss.item() / 1,  i)
writer.close()
